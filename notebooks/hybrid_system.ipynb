{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "0    90.635423\n",
      "1     9.364577\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Hasan\\\\Desktop\\\\data science folder\\\\Fraud_Data_Final.csv\")\n",
    "\n",
    "# Convert timestamps\n",
    "df[\"purchase_time\"] = pd.to_datetime(df[\"purchase_time\"])\n",
    "\n",
    "# Check class distribution\n",
    "print(df[\"class\"].value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   purchase_value  rule_fraud\n",
      "0              34           1\n",
      "1              16           1\n",
      "2              15           0\n",
      "3              44           0\n",
      "4              39           0\n"
     ]
    }
   ],
   "source": [
    "def rule_based_fraud_detection(df):\n",
    "    df[\"rule_fraud\"] = 0  # Default: Not fraud\n",
    "\n",
    "    # Use 'purchase_value' \n",
    "    df.loc[df[\"purchase_value\"] > 10000, \"rule_fraud\"] = 1\n",
    "\n",
    "    # Rule 2: Transactions made between 12 AM - 4 AM\n",
    "    df[\"hour\"] = df[\"purchase_time\"].dt.hour\n",
    "    df.loc[df[\"hour\"].between(0, 4), \"rule_fraud\"] = 1\n",
    "\n",
    "    # Rule 3: Multiple transactions within 10 minutes by the same user\n",
    "    df[\"time_diff\"] = df.groupby(\"user_id\")[\"purchase_time\"].diff().dt.seconds\n",
    "    df.loc[df[\"time_diff\"] < 600, \"rule_fraud\"] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "df = rule_based_fraud_detection(df)\n",
    "print(df[[\"purchase_value\", \"rule_fraud\"]].head())  # Check the rule-based fraud column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hasan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id               int64\n",
      "purchase_value        int64\n",
      "age                   int64\n",
      "ip_address            int64\n",
      "class                 int64\n",
      "rule_fraud            int64\n",
      "hour                  int32\n",
      "time_diff           float64\n",
      "purchase_hour         int32\n",
      "purchase_day          int32\n",
      "purchase_weekday      int32\n",
      "source_Direct          bool\n",
      "source_SEO             bool\n",
      "browser_FireFox        bool\n",
      "browser_IE             bool\n",
      "browser_Opera          bool\n",
      "browser_Safari         bool\n",
      "sex_M                  bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# âœ… Convert timestamps\n",
    "df[\"purchase_time\"] = pd.to_datetime(df[\"purchase_time\"])\n",
    "df[\"signup_time\"] = pd.to_datetime(df[\"signup_time\"])\n",
    "\n",
    "# âœ… Drop unnecessary columns\n",
    "df = df.drop(columns=[\"signup_time\", \"device_id\"])\n",
    "\n",
    "# âœ… Feature Engineering: Extract useful time-based features\n",
    "df[\"purchase_hour\"] = df[\"purchase_time\"].dt.hour\n",
    "df[\"purchase_day\"] = df[\"purchase_time\"].dt.day\n",
    "df[\"purchase_weekday\"] = df[\"purchase_time\"].dt.weekday\n",
    "\n",
    "# âœ… Remove original timestamp columns (they are now encoded in time-based features)\n",
    "df = df.drop(columns=[\"purchase_time\"])\n",
    "\n",
    "# âœ… Convert categorical features to numerical using One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=[\"source\", \"browser\", \"sex\"], drop_first=True)\n",
    "\n",
    "# âœ… Check if all columns are numeric\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule_fraud\n",
      "0             119852\n",
      "1              31260\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def rule_based_fraud_detection(df):\n",
    "    df[\"rule_fraud\"] = 0  # Default: Not fraud\n",
    "\n",
    "    # âœ… Rule 1: Transactions with high value (> $10,000)\n",
    "    df.loc[df[\"purchase_value\"] > 10000, \"rule_fraud\"] = 1\n",
    "\n",
    "    # âœ… Rule 2: Transactions at unusual times (Midnight - 4 AM)\n",
    "    df.loc[df[\"purchase_hour\"].between(0, 4), \"rule_fraud\"] = 1\n",
    "\n",
    "    # âœ… Rule 3: Multiple transactions by the same user within 10 minutes\n",
    "    df[\"time_diff\"] = df.groupby(\"user_id\")[\"purchase_hour\"].diff()\n",
    "    df.loc[df[\"time_diff\"] < 0.167, \"rule_fraud\"] = 1  # 10 minutes = 0.167 hours\n",
    "\n",
    "    return df\n",
    "\n",
    "# âœ… Apply the rule-based system\n",
    "df = rule_based_fraud_detection(df)\n",
    "\n",
    "# âœ… Check rule-based fraud cases\n",
    "print(df[[\"rule_fraud\"]].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Machine Learning Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     27373\n",
      "           1       1.00      0.54      0.70      2850\n",
      "\n",
      "    accuracy                           0.96     30223\n",
      "   macro avg       0.98      0.77      0.84     30223\n",
      "weighted avg       0.96      0.96      0.95     30223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… Define Features (`X`) and Target (`y`)\n",
    "X = df.drop(columns=[\"class\", \"rule_fraud\"])  # Use all features except labels\n",
    "y = df[\"class\"]  # Fraud (1) or Non-Fraud (0)\n",
    "\n",
    "# âœ… Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# âœ… Train a Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# âœ… Evaluate Model Performance\n",
    "print(\"ðŸ”¹ Machine Learning Model Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  rule_fraud  ml_fraud_prob  hybrid_fraud\n",
      "0      0           1           0.08             1\n",
      "1      0           1           0.02             1\n",
      "2      1           0           0.97             1\n",
      "3      0           0           0.00             0\n",
      "4      0           0           0.03             0\n",
      "5      0           0           0.01             0\n",
      "6      0           1           0.02             1\n",
      "7      0           0           0.02             0\n",
      "8      0           0           0.00             0\n",
      "9      0           0           0.02             0\n"
     ]
    }
   ],
   "source": [
    "# âœ… Predict fraud probability using the trained ML model\n",
    "df[\"ml_fraud_prob\"] = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# âœ… Hybrid Fraud Detection: If either Rule-Based OR ML detects fraud, flag it\n",
    "df[\"hybrid_fraud\"] = ((df[\"rule_fraud\"] == 1) | (df[\"ml_fraud_prob\"] > 0.8)).astype(int)\n",
    "\n",
    "# âœ… Compare results\n",
    "print(df[[\"class\", \"rule_fraud\", \"ml_fraud_prob\", \"hybrid_fraud\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Rule-Based System Model Performance:\n",
      "Accuracy: 0.7367\n",
      "Precision: 0.0900\n",
      "Recall: 0.1987\n",
      "\n",
      "ðŸ”¹ ML-Based System Model Performance:\n",
      "Accuracy: 0.9553\n",
      "Precision: 1.0000\n",
      "Recall: 0.5227\n",
      "\n",
      "ðŸ”¹ Hybrid System Model Performance:\n",
      "Accuracy: 0.7764\n",
      "Precision: 0.2363\n",
      "Recall: 0.6221\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, name):\n",
    "    print(f\"\\nðŸ”¹ {name} Model Performance:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "# âœ… Evaluate models\n",
    "evaluate_model(df[\"class\"], df[\"rule_fraud\"], \"Rule-Based System\")\n",
    "evaluate_model(df[\"class\"], (df[\"ml_fraud_prob\"] > 0.8).astype(int), \"ML-Based System\")\n",
    "evaluate_model(df[\"class\"], df[\"hybrid_fraud\"], \"Hybrid System\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hasan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['time_diff']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Training Random Forest...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     27393\n",
      "           1       1.00      0.91      0.95      2830\n",
      "\n",
      "    accuracy                           0.99     30223\n",
      "   macro avg       0.99      0.95      0.97     30223\n",
      "weighted avg       0.99      0.99      0.99     30223\n",
      "\n",
      "\n",
      "ðŸ”¹ Training Logistic Regression...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.49      0.63     27393\n",
      "           1       0.09      0.52      0.16      2830\n",
      "\n",
      "    accuracy                           0.49     30223\n",
      "   macro avg       0.50      0.50      0.40     30223\n",
      "weighted avg       0.83      0.49      0.59     30223\n",
      "\n",
      "\n",
      "ðŸ”¹ Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hasan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     27393\n",
      "           1       1.00      0.91      0.95      2830\n",
      "\n",
      "    accuracy                           0.99     30223\n",
      "   macro avg       0.99      0.95      0.97     30223\n",
      "weighted avg       0.99      0.99      0.99     30223\n",
      "\n",
      "\n",
      "ðŸ”¹ Training SVM...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# âœ… Define Features (`X`) and Target (`y`)\n",
    "drop_cols = [col for col in [\"class\", \"rule_fraud\"] if col in df.columns]\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df[\"class\"]\n",
    "\n",
    "# âœ… Handle missing values using SimpleImputer (mean imputation)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)  # Impute missing values in X\n",
    "\n",
    "# âœ… Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# âœ… Define Machine Learning Models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\"),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    \"SVM\": SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\")\n",
    "}\n",
    "\n",
    "# âœ… Train & Evaluate Each Model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸ”¹ Training {name}...\")\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Predict using the test set\n",
    "    \n",
    "    # Store model results\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=1),\n",
    "        \"Recall\": recall_score(y_test, y_pred, zero_division=1),\n",
    "        \"F1-Score\": 2 * (precision_score(y_test, y_pred) * recall_score(y_test, y_pred)) / (precision_score(y_test, y_pred) + recall_score(y_test, y_pred) + 1e-9)\n",
    "    }\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# âœ… Convert Results to DataFrame for Comparison\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nðŸ”¹ Model Performance Summary:\")\n",
    "print(results_df)\n",
    "\n",
    "# âœ… Select Best Model (Highest Recall)\n",
    "best_model_name = results_df[\"Recall\"].idxmax()\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nâœ… Best Model Selected: {best_model_name}\")\n",
    "\n",
    "# âœ… Predict Fraud Probability using Best ML Model\n",
    "df[\"ml_fraud_prob\"] = best_model.predict_proba(X_imputed)[:, 1]\n",
    "\n",
    "# âœ… Hybrid Fraud Detection: Rule-Based OR ML Model\n",
    "fraud_threshold = 0.6  # Adjust if needed\n",
    "df[\"hybrid_fraud\"] = ((df[\"rule_fraud\"] == 1) | (df[\"ml_fraud_prob\"] > fraud_threshold)).astype(int)\n",
    "\n",
    "# âœ… Compare Results\n",
    "print(df[[\"class\", \"rule_fraud\", \"ml_fraud_prob\", \"hybrid_fraud\"]].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
